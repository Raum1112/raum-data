{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\ssafy\\.conda\\envs\\ai1010\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[현재 진행상황] : 100\n",
      "[현재 진행상황] : 200\n",
      "[현재 진행상황] : 300\n",
      "[현재 진행상황] : 400\n",
      "[현재 진행상황] : 500\n",
      "[현재 진행상황] : 600\n",
      "[현재 진행상황] : 700\n",
      "[현재 진행상황] : 800\n",
      "[현재 진행상황] : 900\n",
      "[현재 진행상황] : 1000\n",
      "[현재 진행상황] : 1100\n",
      "[현재 진행상황] : 1200\n",
      "[현재 진행상황] : 1300\n",
      "[현재 진행상황] : 1400\n",
      "[현재 진행상황] : 1500\n",
      "[현재 진행상황] : 1600\n",
      "[현재 진행상황] : 1700\n",
      "[현재 진행상황] : 1800\n",
      "[현재 진행상황] : 1900\n",
      "[현재 진행상황] : 2000\n",
      "[현재 진행상황] : 2100\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 실제 컬럼명으로 수정하세요\n",
    "cols = ['성분코드', '성분명', '영문명', 'CAS No', '구명칭']\n",
    "ing_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# HTML 테이블 -> 2차원 리스트로 파싱\n",
    "def parse_table_to_list(table_tag):\n",
    "    rows = []\n",
    "    for row in table_tag.find_all('tr'):\n",
    "        cells = row.find_all(['th', 'td'])\n",
    "        cell_texts = [cell.get_text(strip=True) for cell in cells]\n",
    "        if cell_texts:  # 빈 행 제거\n",
    "            rows.append(cell_texts)\n",
    "    return rows\n",
    "\n",
    "# 페이지 루프\n",
    "for num in range(1, 2164):\n",
    "    url = f\"https://kcia.or.kr/cid/search/ingd_list.php?page={num}\"\n",
    "\n",
    "    if num % 100 == 0:\n",
    "        print(f\"[현재 진행상황] : {num}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {\"class\": \"bbs_list\"})\n",
    "\n",
    "        if table:\n",
    "            data_2d = parse_table_to_list(table)\n",
    "            if len(data_2d) > 1:\n",
    "                data_rows = data_2d[1:]  # 첫 줄은 헤더이므로 제거\n",
    "                tmpdf = pd.DataFrame(data_rows, columns=cols)\n",
    "                ing_df = pd.concat([ing_df, tmpdf], ignore_index=True)\n",
    "            else:\n",
    "                print(f\"[주의] {num} 페이지에 데이터 행이 없습니다.\")\n",
    "        else:\n",
    "            print(f\"[경고] {num} 페이지에 테이블이 없습니다.\")\n",
    "\n",
    "        time.sleep(0.3)  # 서버 부하 방지를 위한 딜레이\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"[에러] {num} 페이지 요청 실패: {e}\")\n",
    "\n",
    "ing_df.to_csv('ingredients_data.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성분코드</th>\n",
       "      <th>성분명</th>\n",
       "      <th>영문명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>가공소금</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>가지열매추출물</td>\n",
       "      <td>Solanum Melongena (Eggplant) Fruit Extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>구멍쇠미역추출물</td>\n",
       "      <td>Agarum Cribrosum Extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>루핀아미노산</td>\n",
       "      <td>Lupine Amino Acids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>류신</td>\n",
       "      <td>Leucine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>류코노스톡/무발효여과물</td>\n",
       "      <td>Leuconostoc/Radish Root Ferment Filtrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>백혈구추출물</td>\n",
       "      <td>Leukocyte Extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>리나칸투스 콤무니스추출물</td>\n",
       "      <td>Rhinacanthus Communis Extract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>리날룰</td>\n",
       "      <td>Linalool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>리날릴아세테이트</td>\n",
       "      <td>Linalyl Acetate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   성분코드            성분명                                         영문명\n",
       "0     1           가공소금                                            \n",
       "1     2        가지열매추출물  Solanum Melongena (Eggplant) Fruit Extract\n",
       "2     3       구멍쇠미역추출물                    Agarum Cribrosum Extract\n",
       "3     4         루핀아미노산                          Lupine Amino Acids\n",
       "4     5             류신                                     Leucine\n",
       "5     6   류코노스톡/무발효여과물    Leuconostoc/Radish Root Ferment Filtrate\n",
       "6     7         백혈구추출물                           Leukocyte Extract\n",
       "7     8  리나칸투스 콤무니스추출물               Rhinacanthus Communis Extract\n",
       "8     9            리날룰                                    Linalool\n",
       "9    10       리날릴아세테이트                             Linalyl Acetate"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing_df = ing_df.astype({'성분코드':'int'})\n",
    "ing_df = ing_df[['성분코드', '성분명', '영문명']].set_index('성분코드').sort_index()\n",
    "ing_df.reset_index(inplace=True)\n",
    "ing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\\([^)]*\\)'\n",
    "\n",
    "for idx, row in ing_df.iterrows():\n",
    "    tmp = ing_df.iloc[idx]['영문명']\n",
    "    try:\n",
    "        if '(' in tmp:\n",
    "            txt = re.sub(pattern=pattern, repl='', string= tmp)\n",
    "            txt = ' '.join(txt.split())\n",
    "            ing_df.iloc[idx,2] = txt\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "ing_df['formatted_영문명'] = ing_df['영문명'].str.lower().str.replace(\" \",\"-\") \n",
    "# inci-decoder에 검색가능한 format으로 변경하여 컬럼 추가\n",
    "\n",
    "ing_df.head(10) # 확인 한 번 해주고\n",
    "ing_df.to_csv('ing_data.csv', index=False, encoding='utf-8-sig') # 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_df = pd.read_csv('ing_data.csv',index_col=0)\n",
    "ing_df['formatted_영문명'] = ing_df['formatted_영문명'].str.replace(\"/\",\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_list = list(ing_df['formatted_영문명'].dropna())\n",
    "\n",
    "product_name = set() # 제품명\n",
    "product_label = set() # 제품명 (formatted - 웹페이지 접근용)\n",
    "search_failed = [] # 'formatted_영문명' 값으로 웹페이지 접근이 불가했던 건들 확인용도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20457/20457 [34:33:13<00:00,  6.08s/it]       \n"
     ]
    }
   ],
   "source": [
    "def add_ing_products(tags):  # html tag 를 받아와 조회하여 \n",
    "    for tag in tags:\n",
    "        if tag.text not in product_name: # 중복된 데이터는 추가하지 않도록, tag의 제품명이 product_name 셋에 없는 경우에만 추가\n",
    "            product_name.add(tag.text)\n",
    "            product_label.add(tag.attrs['data-ga-eventlabel'][8:])\n",
    "\n",
    "def next_page_exists(soup):\n",
    "    if \"Next\" in soup.find(id=\"product\").find_all(\"div\")[-1].text: # Next라는 문자가 해당 태그안에 존재하는지 여부 확인\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for ing in tqdm(ing_list):  # 성분 리스트의 각 성분(formatted)마다 \n",
    "    url = 'https://incidecoder.com/ingredients/' + ing  # url 주소를 생성\n",
    "\n",
    "    try:\n",
    "        \n",
    "        html = urlopen(url) \n",
    "        source = html.read()\n",
    "        soup = BeautifulSoup(source, \"html.parser\")\n",
    "        tags = soup.select(\"#product > div > a\")  \n",
    "        add_ing_products(tags)  \n",
    "\n",
    "        if next_page_exists(soup): \n",
    "            nextpage = True\n",
    "\n",
    "        while nextpage:\n",
    "            nexturl = soup.find(id=\"product\").find_all(\"a\")[-1]['href']\n",
    "            url = 'https://incidecoder.com' + nexturl \n",
    "            html = urlopen(url) \n",
    "            source = html.read()\n",
    "            soup = BeautifulSoup(source, \"html.parser\")\n",
    "            tags = soup.select(\"#product > div > a\")\n",
    "            add_ing_products(tags)\n",
    "\n",
    "            if not next_page_exists(soup):\n",
    "                nextpage = False\n",
    "\n",
    "    except Exception:\n",
    "        search_failed.append(ing)\n",
    "        pass\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "    # 100개마다 저장\n",
    "    if idx % 100 == 0:\n",
    "        product_all = pd.DataFrame(columns=['product_label'])\n",
    "        product_all['product_label'] = list(product_label)\n",
    "        product_all.to_csv(f'product_df_{idx}.csv', index=False)\n",
    "\n",
    "# 마지막까지 저장 안 된 것 있으면 추가 저장\n",
    "if idx % 100 != 0:\n",
    "    product_all = pd.DataFrame(columns=['product_label'])\n",
    "    product_all['product_label'] = list(product_label)\n",
    "    product_all.to_csv(f'product_df_{idx}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lissa-retinol-cream-with-spf30', 'vegamour-hydr-8-shampoo', 'dropology-vitamin-c-solution-15']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('product_df_20457.csv')\n",
    "\n",
    "# 2행부터 (인덱스 1부터), 첫 번째 열의 값들을 리스트로 추출\n",
    "product_lst = df.iloc[0:, 0].tolist()\n",
    "\n",
    "# 결과 확인\n",
    "print(product_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda685dbfc804c84a09c1be400ec884f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "제품 정보 수집 중:   0%|          | 0/164098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "product_name = [] # 화장품 이름\n",
    "ingredient_lst = [] # 화장품에 들어있는 성분을 리스트로 받음\n",
    "formatted_ingredient_lst = [] # formatted 성분 표기명을 리스트로 받음\n",
    "what_lst = [] # 성분이 어떤 효능이 있는지 리스트로 받음\n",
    "failed_lst = [] # 크롤링 중 실패한 로그를 추적하기 위해\n",
    "each_ingredient_lst = []\n",
    "\n",
    "# 테이블을 2차원 리스트로 변환하는 함수 (parser_functions.make2d 대체)\n",
    "def parse_table_to_list(table_tag):\n",
    "    rows = []\n",
    "    for row in table_tag.find_all('tr'):\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        cell_texts = [cell.get_text(strip=True) for cell in cells]\n",
    "        if cell_texts:\n",
    "            rows.append(cell_texts)\n",
    "    return rows\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# 제품 목록 루프\n",
    "for product in tqdm(product_lst, desc=\"제품 정보 수집 중\"):\n",
    "    url = f\"https://incidecoder.com/products/{product}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        table = soup.find('table', {\"class\": \"product-skim fs16\"})\n",
    "        if not table:\n",
    "            raise Exception(\"성분 테이블 없음\")\n",
    "\n",
    "        table_data = parse_table_to_list(table)\n",
    "        if len(table_data) <= 1:\n",
    "            raise Exception(\"성분 데이터 없음\")\n",
    "\n",
    "        # 첫 행은 헤더라서 제거\n",
    "        df = table_data[1:]\n",
    "        tmpdf = pd.DataFrame(df, columns=[\"Ingredient name\", \"what-it-does\", \"irr., com.\", \"ID-Rating\"])\n",
    "\n",
    "        # bold 처리된 성분 제거 (formatted_name이 없는 항목)\n",
    "        bold_ings = [td.get_text(strip=True) for td in table.find_all('td', {'class': 'bold'})]\n",
    "        tmpdf = tmpdf[~tmpdf['Ingredient name'].isin(bold_ings)].reset_index(drop=True)\n",
    "\n",
    "        # formatted 성분명 추출\n",
    "        formatted_ings = [\n",
    "            tag['href'][13:] for tag in table.find_all('a', {'class': \"black ingred-detail-link\"})\n",
    "        ]\n",
    "        formatted_ingredient_lst.append(formatted_ings)\n",
    "\n",
    "        # 데이터 수집\n",
    "        ingredient_lst.append(tmpdf['Ingredient name'].tolist())\n",
    "        what_lst.append(tmpdf[\"what-it-does\"].tolist())\n",
    "        product_name.append(product)\n",
    "\n",
    "    except Exception as e:\n",
    "        failed_lst.append([product, str(e)])\n",
    "\n",
    "\n",
    "for lst in ingredient_lst:\n",
    "    for ing in lst:\n",
    "        each_ingredient_lst.append(ing)\n",
    "\n",
    "each_formatted_ingredient_lst = []\n",
    "for lst in formatted_ingredient_lst:\n",
    "    for ing in lst:\n",
    "        each_formatted_ingredient_lst.append(ing)\n",
    "\n",
    "each_what_lst = []\n",
    "for lst in what_lst:\n",
    "    for does in lst:\n",
    "        tmp = []\n",
    "        for does in does.replace('\\n','').replace('\\u200b','').split(','): # 전처리\n",
    "            tmp.append(does.strip())\n",
    "        each_what_lst.append(tmp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 제품명과 성분 리스트로 DataFrame 만들기\n",
    "prod_ing_df = pd.DataFrame({\n",
    "    'product name': product_name,\n",
    "    'ingredients': ingredient_lst\n",
    "})\n",
    "\n",
    "# 2. 성분 리스트를 문자열로 저장하기 위해 JSON 문자열로 변환\n",
    "prod_ing_df['ingredients'] = prod_ing_df['ingredients'].apply(json.dumps)\n",
    "prod_ing_df.to_csv('product_ingredients.csv', index=False)\n",
    "\n",
    "# 1. 성분명과 효능 리스트로 DataFrame 생성\n",
    "ingredient_df = pd.DataFrame({\n",
    "    'ingredients': each_ingredient_lst,\n",
    "    'what-it-does': each_what_lst\n",
    "})\n",
    "\n",
    "# 2. 중복 제거 (같은 성분명은 첫 번째 효능만 유지)\n",
    "ingredient_df = ingredient_df.drop_duplicates(subset='ingredients')\n",
    "\n",
    "# 3. 리스트를 문자열(JSON)로 변환해서 CSV 저장 가능하게 함\n",
    "ingredient_df['what-it-does'] = ingredient_df['what-it-does'].apply(json.dumps)\n",
    "ingredient_df.to_csv('ingredient_functions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be0870d488941d193ead0155498a368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "제품 정보 수집 중:   0%|          | 0/164098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('product_df_20457.csv')\n",
    "\n",
    "# 2행부터 (인덱스 1부터), 첫 번째 열의 값들을 리스트로 추출\n",
    "product_lst = df.iloc[0:, 0].tolist()\n",
    "# 제품명 끝에 -2, -3, -4 와 같은 제품들만 한번 더 추출해서 그 위 아래값들을 조사\n",
    "\n",
    "product_name = [] # 화장품 이름\n",
    "ingredient_lst = [] # 화장품에 들어있는 성분을 리스트로 받음\n",
    "formatted_ingredient_lst = [] # formatted 성분 표기명을 리스트로 받음\n",
    "what_lst = [] # 성분이 어떤 효능이 있는지 리스트로 받음\n",
    "failed_lst = [] # 크롤링 중 실패한 로그를 추적하기 위해\n",
    "each_ingredient_lst = []\n",
    "\n",
    "def parse_table_to_list(table_tag):\n",
    "    rows = []\n",
    "    for row in table_tag.find_all('tr'):\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        cell_texts = [cell.get_text(strip=True) for cell in cells]\n",
    "        if cell_texts:\n",
    "            rows.append(cell_texts)\n",
    "    return rows\n",
    "\n",
    "for product in tqdm(product_lst, desc=\"제품 정보 수집 중\"):\n",
    "    if product[-2] == \"-\" and product[-1].isdigit():\n",
    "        num = int(product[-2::])\n",
    "        for idx in range(1, 10):\n",
    "            if idx == num:\n",
    "                continue\n",
    "            productURL = product\n",
    "            if idx == 1:\n",
    "                productURL = product[:-2]\n",
    "            else:\n",
    "                productURL = product[:-1] + str(idx)\n",
    "\n",
    "            url = f\"https://incidecoder.com/products/{productURL}\"\n",
    "\n",
    "            try:\n",
    "                response = requests.get(url, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                table = soup.find('table', {\"class\": \"product-skim fs16\"})\n",
    "                if not table:\n",
    "                    raise Exception(\"성분 테이블 없음\")\n",
    "\n",
    "                table_data = parse_table_to_list(table)\n",
    "                if len(table_data) <= 1:\n",
    "                    raise Exception(\"성분 데이터 없음\")\n",
    "\n",
    "                # 첫 행은 헤더라서 제거\n",
    "                df = table_data[1:]\n",
    "                tmpdf = pd.DataFrame(df, columns=[\"Ingredient name\", \"what-it-does\", \"irr., com.\", \"ID-Rating\"])\n",
    "\n",
    "                # bold 처리된 성분 제거 (formatted_name이 없는 항목)\n",
    "                bold_ings = [td.get_text(strip=True) for td in table.find_all('td', {'class': 'bold'})]\n",
    "                tmpdf = tmpdf[~tmpdf['Ingredient name'].isin(bold_ings)].reset_index(drop=True)\n",
    "\n",
    "                # formatted 성분명 추출\n",
    "                formatted_ings = [\n",
    "                    tag['href'][13:] for tag in table.find_all('a', {'class': \"black ingred-detail-link\"})\n",
    "                ]\n",
    "                formatted_ingredient_lst.append(formatted_ings)\n",
    "\n",
    "                # 데이터 수집\n",
    "                ingredient_lst.append(tmpdf['Ingredient name'].tolist())\n",
    "                what_lst.append(tmpdf[\"what-it-does\"].tolist())\n",
    "                product_name.append(productURL)\n",
    "\n",
    "            except Exception as e:\n",
    "                break\n",
    "\n",
    "for lst in ingredient_lst:\n",
    "    for ing in lst:\n",
    "        each_ingredient_lst.append(ing)\n",
    "\n",
    "each_formatted_ingredient_lst = []\n",
    "for lst in formatted_ingredient_lst:\n",
    "    for ing in lst:\n",
    "        each_formatted_ingredient_lst.append(ing)\n",
    "\n",
    "each_what_lst = []\n",
    "for lst in what_lst:\n",
    "    for does in lst:\n",
    "        tmp = []\n",
    "        for does in does.replace('\\n','').replace('\\u200b','').split(','): # 전처리\n",
    "            tmp.append(does.strip())\n",
    "        each_what_lst.append(tmp)\n",
    "\n",
    "# 1. 제품명과 성분 리스트로 DataFrame 만들기\n",
    "prod_ing_df = pd.DataFrame({\n",
    "    'product name': product_name,\n",
    "    'ingredients': ingredient_lst\n",
    "})\n",
    "\n",
    "# 2. 성분 리스트를 문자열로 저장하기 위해 JSON 문자열로 변환\n",
    "prod_ing_df['ingredients'] = prod_ing_df['ingredients'].apply(json.dumps)\n",
    "prod_ing_df.to_csv('product_ingredients_append_edge_case.csv', index=False)\n",
    "\n",
    "# 1. 성분명과 효능 리스트로 DataFrame 생성\n",
    "ingredient_df = pd.DataFrame({\n",
    "    'ingredients': each_ingredient_lst,\n",
    "    'what-it-does': each_what_lst\n",
    "})\n",
    "\n",
    "# 2. 중복 제거 (같은 성분명은 첫 번째 효능만 유지)\n",
    "ingredient_df = ingredient_df.drop_duplicates(subset='ingredients')\n",
    "\n",
    "# 3. 리스트를 문자열(JSON)로 변환해서 CSV 저장 가능하게 함\n",
    "ingredient_df['what-it-does'] = ingredient_df['what-it-does'].apply(json.dumps)\n",
    "ingredient_df.to_csv('ingredient_functions_append_edge_case.csv', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 완료! 결과는 ingredient_functions_merged.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 읽기\n",
    "df1 = pd.read_csv('ingredient_functions.csv')\n",
    "df2 = pd.read_csv('ingredient_functions_append_edge_case.csv')\n",
    "\n",
    "# 1열 기준 병합 (첫 번째 열의 이름을 알아야 합니다. 모를 경우 df1.columns[0]으로 가져옵니다)\n",
    "key_col = df1.columns[0]\n",
    "\n",
    "# 두 데이터프레임을 합치고, 중복 제거\n",
    "merged_df = pd.concat([df1, df2]).drop_duplicates(subset=[key_col])\n",
    "\n",
    "# 결과 저장\n",
    "merged_df.to_csv('ingredient_functions_merged.csv', index=False)\n",
    "print(\"✅ 병합 완료! 결과는 ingredient_functions_merged.csv로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 완료! 결과는 product_ingredients_merged.csv로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 읽기\n",
    "df1 = pd.read_csv('product_ingredients.csv')\n",
    "df2 = pd.read_csv('product_ingredients_append_edge_case.csv')\n",
    "\n",
    "# 1열 기준 병합 (첫 번째 열의 이름을 알아야 합니다. 모를 경우 df1.columns[0]으로 가져옵니다)\n",
    "key_col = df1.columns[0]\n",
    "\n",
    "# 두 데이터프레임을 합치고, 중복 제거\n",
    "merged_df = pd.concat([df1, df2]).drop_duplicates(subset=[key_col])\n",
    "\n",
    "# 결과 저장\n",
    "merged_df.to_csv('product_ingredients_merged.csv', index=False)\n",
    "print(\"✅ 병합 완료! 결과는 product_ingredients_merged.csv로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNREl4Wsqtb2//8CtjVIWOu",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai1010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
